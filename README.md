# Detector de Mensajes de Odio en YouTube

## üìù Descripci√≥n
Nota: Este proyecto est√° realizado dentro del bootcamp de IA de Factor√≠a F5, que tuvo lugar entre mayo de 2024 y marzo de 2025. Es un proyecto realizado en parejas que corresponde a la parte de NLP.
Sistema de detecci√≥n y an√°lisis de mensajes de odio en comentarios de YouTube utilizando Deep Learning y Natural Language Processing. Implementado con Redes Neuronales Convolucionales  y Streamlit.

## üõ†Ô∏è Tecnolog√≠as Principales
- **Frontend**: Streamlit
- **Backend**: Python 3.8+
- **Deep Learning**: TensorFlow 2.15.0
- **Base de Datos**: MongoDB 4.6.1 , Mongo-Express 1.0.2
- **NLP**: NLTK 3.8.1, Spacy 3.7.2
- **API**: YouTube Data API v3

## üìã Requisitos del Sistema
- Python 3.8 o superior
- MongoDB instalado y en ejecuci√≥n
- Memoria RAM: 8GB m√≠nimo recomendado
- Espacio en disco: 2GB m√≠nimo
- GPU recomendada para entrenamiento del modelo

## ‚öôÔ∏è Instalaci√≥n

1. **Clonar el repositorio**
```bash
git clone <url-repositorio>
cd <nombre-directorio>
```

2. **Crear y activar entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
Crear archivo `.env` con:
```
YOUTUBE_API_KEY=tu_api_key
MONGO_URI=mongodb://localhost:27017/
DATABASE_NAME=NLP
COLLECTION_NAME=lebels
```

## üìÅ Estructura del Proyecto
```
proyecto/
‚îú‚îÄ‚îÄ data/                  # Datos de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ youtoxic_english_1000.csv
‚îú‚îÄ‚îÄ models/               # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ final_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer.pickle
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ youtube_api.py   # Cliente API YouTube
‚îÇ   ‚îú‚îÄ‚îÄ app.py          # Aplicaci√≥n principal
‚îÇ   ‚îî‚îÄ‚îÄ rnn_antioverfitting.py  # Entrenamiento
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄdocker-compose.yml 
‚îú‚îÄ‚îÄ .dockerfile
‚îî‚îÄ‚îÄdocker-compose.yml 
```

## üöÄ Uso

### Iniciar la Aplicaci√≥n
```bash
streamlit run src/app.py
```

### Funcionalidades Principales
1. **An√°lisis Individual**
   - Analiza comentarios individuales
   - Muestra probabilidad de contenido ofensivo

2. **An√°lisis de Videos**
   - Analiza todos los comentarios de un video
   - Genera estad√≠sticas y visualizaciones

3. **Monitoreo Continuo**
   - Seguimiento en tiempo real
   - Exportaci√≥n de resultados

## üì¶ Dependencias Principales
```
numpy>=1.26.2
pandas>=2.1.4
tensorflow>=2.15.0
streamlit>=1.29.0
pymongo>=4.6.1
nltk>=3.8.1
scikit-learn>=1.3.2
```

## üîß Configuraci√≥n del Modelo
```python
MAX_WORDS = 15000
MAX_LEN = 128
EMBEDDING_DIM = 200
```

## üìä Entrenamiento del Modelo
Para entrenar el modelo:
```bash
python src/rnn_antioverfitting.py
```

## ü§ù Contribuci√≥n
1. Fork del proyecto
2. Crear rama de feature
   ```bash
   git checkout -b feature/NuevaFeature
   ```
3. Commit y push
4. Crear Pull Request


## Visionado de experimientos en MLflow
1. En la rama experimentos-con-mlflow est√°n registradas las m√©tricas del modelo entrenado alterando el hiperpar√°metro de batch-size (16, 32, 64, 128)
2.    Ejecutar el comando
 ```bash
  mlflow ui  
   ```

3. La terminal ofrece el servidor donde se pueden consultar los experimentos
# FUNCIONAMIENTO DEL MODELO
# üéØ **Objetivo del Modelo**

El modelo busca detectar texto ofensivo o t√≥xico mediante t√©cnicas avanzadas de procesamiento de lenguaje natural y deep learning.

## 1. Datos de Entrada

### Fuente de Datos
* Archivo CSV: 'youtoxic_english_1000.csv'
* Contiene textos con etiquetas de diferentes tipos de ofensividad:
   * IsAbusive
   * IsProvocative
   * IsObscene
   * IsHatespeech
   * IsRacist

### Preprocesamiento de Datos

1. **Limpieza de Texto**:
   * Convertir a min√∫sculas
   * Eliminar URLs
   * Eliminar caracteres especiales
   * Lematizaci√≥n (reducir palabras a su forma base)
   * Eliminar stopwords

2. **Aumento de Datos** (Data Augmentation):
   * Para textos ofensivos, se generan variaciones usando:
      * Sustituci√≥n de sin√≥nimos
      * Back-translation (traducir y re-traducir)
      * Eliminaci√≥n aleatoria de palabras

## 2. Arquitectura del Modelo

El modelo es una red neuronal profunda con las siguientes capas:

### A. Embedding Layer
* Convierte palabras en vectores densos
* Usa embeddings preentrenados de GloVe (Twitter)
* Dimensi√≥n: 200

### B. Procesamiento Convolucional
* Capa Conv1D para extraer caracter√≠sticas locales
* Filtros ajustables
* Kernel de 5 palabras
* Activaci√≥n ReLU

### C. LSTM Bidireccional
* Analiza secuencias en ambas direcciones
* Captura contexto complejo
* Regularizaci√≥n para prevenir overfitting

### D. Capas Densas
* Combinan caracter√≠sticas extra√≠das
* Capa final con activaci√≥n sigmoidal
* Salida: Probabilidad binaria de ser texto ofensivo

## 3. T√©cnicas Anti-Overfitting

1. Regularizaci√≥n L2
2. Dropout (40-50%)
3. BatchNormalization
4. Learning Rate Decay
5. Early Stopping
6. Reducci√≥n de Learning Rate

## 4. Entrenamiento

### Estrategias
* Validaci√≥n cruzada estratificada (5 folds)
* Balanceo de clases con class weights
* M√©tricas:
   * Accuracy
   * AUC
   * Precisi√≥n
   * Recall
   * F1-Score

### Divisi√≥n de Datos
* 90% para entrenamiento/validaci√≥n
* 10% para test final

## 5. Seguimiento de Experimentos

Usa MLflow para:
* Registrar hiperpar√°metros
* Trackear m√©tricas
* Guardar modelos
* Detectar posible overfitting

## 6. Caracter√≠sticas Innovadoras

* Diccionario expandido de palabras ofensivas
* T√©cnicas avanzadas de aumento de datos
* M√©tricas personalizadas
* Regularizaci√≥n multi-nivel

## Ejemplo de Flujo

`Texto de entrada ‚Üí Limpieza ‚Üí Tokenizaci√≥n ‚Üí Embedding ‚Üí Convoluci√≥n ‚Üí LSTM ‚Üí Clasificaci√≥n Binaria (Ofensivo/No Ofensivo)`

## Consideraciones Finales

‚úÖ Modelo robusto para clasificaci√≥n de texto t√≥xico
‚úÖ Aproximaci√≥n t√©cnica para detecci√≥n autom√°tica
‚ùó Requiere datos de calidad y diversidad
